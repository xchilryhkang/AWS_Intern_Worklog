[
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Trang Hoàng Khang\nSố điện thoại: 0837525888\nEmail: khangthse182228@fpt.edu.vn\nTrường: Đại học FPT TP.HCM\nNgành: Trí tuệ nhân tạo\nMSSV SE182228\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 08/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Cách một khách hàng giảm 28% tổng chi phí sở hữu (TCO) cho việc lưu trữ với Amazon FSx for NetApp ONTAP bởi Sachin Bawse và Vishnu Vashist | vào ngày 08 tháng 9 năm 2025 | trong chuyên mục Advanced (300), Amazon FSx for NetApp ONTAP, Best Practices, Healthcare, Technical How-to | Permalink\nCác tổ chức có nhiều chi nhánh thường gặp thách thức lớn trong việc quản lý hệ thống tệp phân tán, đặc biệt khi sử dụng hạ tầng tại chỗ (on-premises) truyền thống. Việc duy trì khả năng chia sẻ tệp mượt mà giữa các vị trí địa lý khác nhau, đồng thời đảm bảo tính bảo mật, hiệu quả trong quản lý dữ liệu và xác thực người dùng đáng tin cậy, ngày càng trở nên phức tạp trong bối cảnh số hóa hiện nay.\nAmazon FSx for NetApp ONTAP giải quyết những thách thức này bằng cách cung cấp một giải pháp cloud-native được quản lý hoàn toàn, mang lại khả năng lưu trữ tệp hiệu năng cao với tích hợp sẵn tính năng sao chép dữ liệu (replication), đồng bộ tự động và bộ nhớ đệm thông minh (intelligent caching).\nTrong bài viết này, nhóm tác giả chia sẻ cách một khách hàng đã triển khai FSx for ONTAP với cấu hình Multi-AZ, sử dụng NetApp FlexCache cho bộ nhớ đệm cục bộ và thực hiện di chuyển dữ liệu bằng SnapMirror. Trong quá trình này, họ thực hiện các bài kiểm tra hiệu năng, phân tích các đánh đổi trong thiết kế kiến trúc và đưa ra so sánh chi phí — cho thấy mức giảm 28% chi phí sở hữu tổng thể (TCO) so với giải pháp tại chỗ truyền thống.\nTổng quan giải pháp Kiến trúc cốt lõi của giải pháp xoay quanh việc triển khai Amazon FSx for NetApp ONTAP Multi-AZ cluster trải rộng trên hai Vùng sẵn sàng (Availability Zones), nhằm đảm bảo tính sẵn sàng cao và khả năng chịu lỗi.\nCác chi nhánh kết nối tới FSxN thông qua các kết nối VPN bảo mật, truy cập dữ liệu thông qua ONTAP FlexCache volumes được triển khai tại môi trường on-prem hoặc VMware. Các bộ nhớ đệm này giúp giảm băng thông và cải thiện tốc độ phản hồi nhờ phục vụ dữ liệu được truy cập thường xuyên ngay tại chỗ.\nViệc di chuyển dữ liệu được thực hiện bằng NetApp SnapMirror, đảm bảo sao chép dữ liệu nhất quán từ kho lưu trữ on-prem lên AWS.\nHình 1: Hệ thống tệp phân tán với kiến trúc Amazon FSx hoặc NetApp ONTAP. Các lớp giao tiếp và bộ nhớ đệm bao gồm: • Chi nhánh địa phương → FlexCache volumes (phục vụ dữ liệu nóng) • FlexCache → FSx ONTAP origin cluster trên các AZ • SnapMirror → sao chép dữ liệu lên FSx, duy trì hiệu quả lưu trữ\nKhách hàng cũng tiến hành so sánh hiệu năng: khi truyền một tệp 50 MB, ONTAP Select cache kết nối FSx đạt 26,09 giây, so với 24,20 giây trên máy chủ tệp cục bộ, cho thấy hiệu năng gần tương đương với lưu trữ tại chỗ.\nCân nhắc về độ trễ và ghi lại FlexCache Tính năng ghi lại (write-back) của FlexCache đặc biệt hữu ích khi độ trễ (latency) giữa bộ nhớ đệm chi nhánh và cụm gốc vượt quá 8 ms. Trong điều kiện đó, bộ nhớ đệm giúp cải thiện hiệu năng ghi dữ liệu đáng kể.\nMột số yêu cầu thiết kế cần lưu ý: • CPU \u0026amp; RAM: Mỗi nút trong cụm gốc cần ít nhất 128 GB RAM và khoảng 20 vCPUs để xử lý tải write-back. • Phiên bản ONTAP: Cụm gốc và cụm cache phải chạy ONTAP 9.15.1 trở lên để hỗ trợ write-back. • Giấy phép (Licensing): FlexCache (bao gồm cả write-back) đã được tích hợp sẵn, không cần mua thêm license. • Cluster peering: Cụm gốc và cụm cache cần được kết nối ngang hàng (peered), các server virtual machines SVMs cũng cần được vserver-peered với FlexCache bật.\nNhững nguyên tắc này giúp đảm bảo bộ nhớ đệm hoạt động ổn định trong các mô hình chi nhánh phân tán.\nGiám sát và khả năng hiển thị Để có cái nhìn chi tiết hơn về hiệu suất và hoạt động của FSx \u0026amp; ONTAP ngoài dữ liệu mặc định trên Amazon CloudWatch, giải pháp sử dụng NetApp Harvest kết hợp với Grafana. Công cụ Harvest thu thập các chỉ số như hiệu năng, tỷ lệ cache hit, mức độ hiệu quả lưu trữ, và thống kê cấp volume, giúp quản trị viên có khả năng theo dõi chi tiết và chủ động tối ưu hóa.\nƯớc tính TCO so với on-premises Để định lượng lợi ích về chi phí, khách hàng đã mô hình hóa một kịch bản lai (hybrid) để so sánh giữa FSx for ONTAP (Multi-AZ, cấu hình SSD + capacity tier tỉ lệ khoảng 30/70, throughput ~256 MB/s) với hệ thống tại chỗ tương đương. Kết quả cho thấy FSx for ONTAP giúp giảm ước tính 28% tổng chi phí sở hữu (TCO) so với giải pháp tại chỗ, nhờ giảm chi phí vận hành, tăng hiệu quả lưu trữ, và đơn giản hóa hạ tầng quản lý.\nKết Luận Amazon FSx for NetApp ONTAP là một giải pháp mạnh mẽ cho các hệ thống tệp phân tán, đặc biệt phù hợp với mô hình nhiều chi nhánh.\nThông qua triển khai Multi-AZ, FlexCache để lưu đệm cục bộ, SnapMirror để di chuyển dữ liệu, cùng hệ thống giám sát chi tiết, kiến trúc này mang lại hiệu năng gần như cục bộ, độ sẵn sàng cao, và giảm 28% TCO so với on-premises.\nChiến lược triển khai này cho thấy cách tích hợp lưu trữ đám mây hiện đại có thể khắc phục các hạn chế truyền thống về băng thông, tính nhất quán và độ phức tạp vận hành trong các hệ thống phân tán nhiều địa điểm.\nTác Giả Sachin Bawse\nSachin là Kiến trúc sư Giải pháp Chuyên gia về Lưu trữ (GTM Specialist Storage Solution Architect) tại Amazon Web Services (AWS), nơi anh chuyên về tối ưu hóa các giải pháp lưu trữ, hỗ trợ di chuyển dữ liệu, và nâng cao hiệu suất khối lượng công việc cho khách hàng. Ngoài công việc, Sachin là một người đam mê khám phá, thích du lịch đến những điểm đến mới, tìm hiểu các nền văn hóa khác nhau và thưởng thức ẩm thực đa dạng. Vishnu Vashist\nVishnu Vashist là Kiến trúc sư Giải pháp Thành công Đối tác (Partner Success Solutions Architect) trong bộ phận Đối tác (Partner Org) của AWS, nơi anh phụ trách các tài khoản thuộc lĩnh vực Y tế, Chăm sóc sức khỏe, Khoa học đời sống (HCLS) cũng như Du lịch, Vận tải và Logistics. Anh chuyên về di chuyển và hiện đại hóa hệ thống, hỗ trợ các dự án di chuyển quy mô lớn lên AWS và hướng dẫn khách hàng cùng đối tác về thiết kế kiến trúc và hạ tầng trên AWS. "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Cloud Day” Mục Đích Của Sự Kiện Giới thiệu xu hướng phát triển của AI tại Việt Nam và cơ hội kinh tế. Trình bày sự tiến hóa từ Generative AI đến Agentic AI. Giới thiệu các giải pháp của AWS như Amazon Bedrock, AgentCore, và SageMaker Unified Studio trong việc xây dựng, triển khai và vận hành AI agent. Danh Sách Diễn Giả \u0026lt;Điền tên diễn giả tại đây\u0026gt; \u0026lt;Điền thêm nếu có\u0026gt; Nội Dung Nổi Bật Tác động của AI đến kinh tế Việt Nam AI có thể đóng góp 120–130 tỷ USD vào GDP Việt Nam vào năm 2040 (~25%). Thị trường AI trị giá 750 triệu USD, tăng trưởng 15–18%/năm. Việt Nam hiện có 765 startup AI, đứng thứ 2 ASEAN. Cơ hội lớn nhưng vẫn ở giai đoạn đầu, cần thêm hạ tầng, nhân tài và chính sách. Sự tiến hóa của AI → Agentic AI Generative AI Assistants → Generative AI Agents → Agentic AI Systems. Các hệ thống AI ngày càng ít phụ thuộc con người: Multi-agent systems: các agent phối hợp cùng nhau giải quyết tác vụ phức tạp. Mức độ tự động hóa tăng dần, giảm dần sự giám sát của con người: Ứng dụng của Agentic AI trong tổ chức Nâng cao năng suất làm việc, tự động hóa quy trình, thúc đẩy đổi mới và nghiên cứu. Dự đoán đến 2028, 33% ứng dụng doanh nghiệp sẽ tích hợp Agentic AI. 15% quyết định thường ngày trong doanh nghiệp sẽ được đưa ra tự động nhờ Agentic AI. Amazon Bedrock – Nền tảng AI toàn diện Cung cấp đa dạng mô hình từ nhiều hãng hàng đầu. Cho phép tùy chỉnh mô hình với dữ liệu riêng, đảm bảo bảo mật và kiểm soát chi phí. Tích hợp Responsible AI checks để đảm bảo an toàn. Hỗ trợ triển khai và vận hành agent nhanh chóng, an toàn và mở rộng dễ dàng. Amazon Bedrock AgentCore Môi trường triển khai và vận hành Agent bảo mật, có khả năng mở rộng cao. Hỗ trợ các framework: LangChain, CrewAI, LangGraph, Strands Agents. Quản lý short-term và long-term memory, có truy xuất ngữ nghĩa (semantic search). Tích hợp và khám phá tool dễ dàng. Hạ tầng dữ liệu và AI Giới thiệu Amazon SageMaker Unified Studio – trung tâm hợp nhất dữ liệu, phân tích và AI. Kết nối chặt chẽ với: Amazon Redshift, Athena, EMR, Glue – xử lý và lưu trữ dữ liệu. Amazon QuickSight – trực quan hóa dữ liệu. Amazon Bedrock – phát triển ứng dụng GenAI. Hỗ trợ tích hợp Zero-ETL giữa S3 data lake và Redshift data warehouse. Data Lakehouse Hỗ trợ nhiều loại lưu trữ: S3 Tables, Redshift Managed Storage. Kết nối các nguồn dữ liệu lớn: Aurora, DynamoDB, MSK, Kinesis, OpenSearch, Salesforce, SAP, Facebook Ads. Những Gì Học Được Về Tư Duy AI và Cloud Hiểu được xu hướng Agentic AI là giai đoạn tiếp theo của Generative AI và đang hot hiện tại. Agentic AI không chỉ là Chatbot mà là hệ thống có thể hành động và tự ra quyết định. Nắm bắt cách AWS Bedrock cung cấp nền tảng cho doanh nghiệp xây dựng hệ thống AI thông minh. Thấy rõ tầm quan trọng của AI agents trong tự động hóa doanh nghiệp và sáng tạo. Về Kiến Trúc Kỹ Thuật Hiểu mối liên kết giữa Bedrock – SageMaker – Redshift – S3 trong một hệ sinh thái AI hoàn chỉnh. Nắm được cách AWS xử lý memory, tool discovery, và observability cho AI agent. Ứng Dụng Vào Công Việc Áp dụng Amazon Berock cho dự án hiện tại: Sử dụng Amazon Titan Embeddings để tạo embedding Thử nghiệm Zero-ETL với Amazon Redshift để đơn giản hóa pipeline dữ liệu từ Aurora/DynamoDB. Đánh giá việc sử dụng Amazon Bedrock AgentCore để xây dựng các tác tử AI tự động hóa quy trình nghiệp vụ (thay vì chỉ dùng Lambda + Bedrock cơ bản). Trải nghiệm trong Sự Kiện Tham gia sự kiện Cloud Day là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn rõ ràng hơn về cách các doanh nghiệp đang ứng dụng AI để hiện đại hóa hệ thống và nâng cao năng suất.\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS chia sẻ sâu về Agentic AI và sự khác biệt so với Generative AI truyền thống. Qua các ví dụ thực tế của Amazon, tôi hiểu rõ hơn cách họ triển khai multi-agent systems để tối ưu quy trình doanh nghiệp. Trải nghiệm kỹ thuật thực tế Tìm hiểu cách hoạt động của Amazon Bedrock AgentCore, từ cách nó xử lý short/long-term memory đến quản lý công cụ tích hợp. Thấy rõ quy trình kết nối dữ liệu từ S3 – Redshift – SageMaker, và cách AI agents truy xuất dữ liệu để trả lời theo ngữ cảnh. Hiểu rõ mô hình Lakehouse và cơ chế Zero-ETL integration giữa data lake và data warehouse. Ứng dụng công cụ hiện đại Học cách triển khai Agentic AI nhanh chóng trên AWS Bedrock, với độ bảo mật và khả năng mở rộng cao. Bài học rút ra Agentic AI không chỉ là công nghệ mới, mà là bước tiến chiến lược để doanh nghiệp đạt tự động hóa cấp hệ thống. Hạ tầng AI hiện đại cần được thiết kế dựa trên dữ liệu và cloud-native architecture. AWS đang dẫn đầu trong việc cung cấp nền tảng toàn diện cho AI/ML, đặc biệt là Bedrock và SageMaker. Thấy rõ tầm quan trọng của AI agents trong tự động hóa doanh nghiệp và sáng tạo. Một Số Hình Ảnh Khi Tham Gia Sự Kiện Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Generative AI with Amazon Bedrock” Mục Đích Của Sự Kiện Cung cấp kiến thức nền tảng về Generative AI và sự khác biệt so với Machine Learning truyền thống. Mô tả chi tiết về dịch vụ Amazon Bedrock và các mô hình nền tảng (Foundation Models). Hướng dẫn kỹ thuật về RAG (Retrieval Augmented Generation) để xây dựng ứng dụng AI thông minh, chính xác và tránh ảo giác. Giới thiệu hệ sinh thái các dịch vụ AI chuyên biệt của AWS. Danh Sách Diễn Giả Lam Tuan Kiet - Sr DevOps Engineer, FPT Software. Danh Hoang Hieu Nghi - AI Engineer, Renova Cloud. Dinh Le Hoang Anh - Cloud Engineer Trainee, First Cloud AI Journey. Nội Dung Nổi Bật Sự chuyển dịch: Traditional ML vs Foudation Models Traditional ML Models: Chuyên biệt cho từng tác vụ cụ thể (Specific tasks), cần dữ liệu được gán nhãn (Labeled data), quy trình Train/Deploy phức tạp cho từng mục đích. Foundation Models (FM): Được huấn luyện trên dữ liệu phi cấu trúc khổng lồ (Unlabeled data), có khả năng thích ứng cho nhiều tác vụ khác nhau như: Text generation, Summarization, Q\u0026amp;A, Chatbot. Hệ sinh thái AI trên AWS Amazon Bedrock: Nơi hội tụ các mô hình FM hàng đầu từ các đối tác của AWS(AI21 Labs, Anthropic, Cohere, Meta, Stability AI,\u0026hellip;) và mô hình của Amazon. AWS Specialized AI Services: Các dịch vụ AI của AWS có thể gọi là \u0026ldquo;mì ăn liền\u0026rdquo; được tối ưu cho tác vụ cụ thể mà không cần train mô hình: Amazon Rekognition: Phát hiện đối tượng, Nhận diện khuôn mặt, Nhận diện cảm xúc, Nhận diện cảm xúc, Nhận diện người nổi tiếng, phân tích video - 0.001$/ảnh với 1 triệu ảnh đầu tiên Amazon translate: Dịch thuật văn bản đa ngôn ngữ theo thời gian thực với độ chính xác cao và văn phong tự nhiên. Amazon Textract: Trích xuất thông tin có cấu trúc (bảng biểu, form mẫu) từ văn bản quét hoặc PDF. Amazon Transcribe: Chuyển đổi giọng nói thành văn bản Amazon Polly: Chuyển đổi văn bản thành giọng nói. Amazon Comprehend: Phân tích cảm xúc văn bản, trích xuất từ khóa và phân loại chủ đề tự động. Amazon Kendra: Cho phép hỏi đáp bằng ngôn ngữ tự nhiên để tìm thông tin trong tài liệu nội bộ của doanh nghiệp. Amazon Lookout: Phát hiện các bất thường trong dây chuyền sản xuất hoặc máy móc công nghiệp để bảo trì dự đoán. Amazon Personalize: Xây dựng hệ thống gợi ý theo thời gian thực, sử dụng công nghệ máy học. Kỹ thuật Prompting: Chain of Thought (CoT) So sánh giữa Standard Prompting là hỏi thẳng kết quả và Chain-of-Thought Prompting. CoT hướng dẫn mô hình suy luận từng bước để giải quyết các bài toán logic phức tạp, giúp tăng độ chính xác đáng kể so với việc chỉ đưa ra đáp án cuối cùng. RAG (Retrieval Augmented Generation) – Trọng tâm kỹ thuật Vấn đề: Giải quyết hiện tượng \u0026ldquo;ảo giác\u0026rdquo; và thiếu kiến thức cập nhật của LLM. Giải pháp: Kết hợp khả năng truy xuất dữ liệu (Retrieval) từ Knowledge Base bên ngoài với khả năng tạo sinh (Generation) của LLM. Quy trình Data Ingestion (Nạp dữ liệu): Dữ liệu thô (New data) $\\rightarrow$ Chia nhỏ (Chunking). Đi qua Embeddings model (ví dụ: Amazon Titan Text Embeddings V2.0). Lưu trữ dưới dạng vector vào Vector Store (OpenSearch Serverless, Pinecone, Redis\u0026hellip;). RetrieveAndGenerate API: API quản lý toàn bộ quy trình từ nhận input người dùng $\\rightarrow$ tạo query embedding $\\rightarrow$ truy xuất dữ liệu $\\rightarrow$ bổ sung ngữ cảnh (augment prompt) $\\rightarrow$ sinh câu trả lời. Những Gì Học Được Về Tư Duy AI và Cloud Hiểu rõ khi nào nên dùng Specialized AI Services cho bài toán nhanh, cụ thể và khi nào dùng Bedrock/GenAI cho bài toán sáng tạo, phức tạp. Nắm vững tư duy thiết kế hệ thống RAG: Không chỉ là gọi API của LLM, mà là bài toán quản lý dữ liệu và vector hóa để cung cấp ngữ cảnh đúng cho AI tạo phản hồi chuẩn hơn. Về Kiến Trúc Kỹ Thuật Kỹ thuật Chain of Thought là chìa khóa để tối ưu hóa kết quả đầu ra của mô hình mà không cần fine-tuning. Hiểu sâu về vai trò của Amazon Titan Embeddings V2.0 trong việc chuyển đổi văn bản đa ngôn ngữ thành vector (hỗ trợ 100+ ngôn ngữ, vector size linh hoạt 256/512/1024). Ứng Dụng Vào Công Việc Áp dụng Amazon Berock cho dự án hiện tại: Amazon Rekognition: nhận diện món ăn từ ảnh để tự động điền thông tin calo, Amazon Comprehend: phân tích text để chuẩn hóa món ăn lấy và ghi dữ liệu calo. Áp dụng thử kĩ thuật RAG cho dự án hiện tại. Sử dụng Bedrock Agents để điều phối các tác vụ như truy vấn món ăn từ vector store, tính toán mục tiêu calo và xây dựng thực đơn từng ngày. Trải nghiệm trong Sự Kiện Tham gia buổi workshop Generative AI with Amazon Bedrock mang lại cái nhìn rất thực tế về cách xây dựng ứng dụng AI hiện đại, đi từ lý thuyết nền tảng đến triển khai thực tế.\nKiến thức thực chiến từ chuyên gia Các diễn giả đã giải thích khá rõ ràng luồng đi của dữ liệu trong một hệ thống RAG, giúp tôi hình dung được \u0026ldquo;hộp đen\u0026rdquo; phía sau các ứng dụng Chatbot hiện nay đang sử dụng. Việc phân tích rõ ràng giữa Traditional ML và Generative AI giúp tôi định hình lại chiến lược chọn công nghệ cho các dự án sắp tới. Trải nghiệm công nghệ Ấn tượng với RetrieveAndGenerate API của Bedrock vì nó giúp giảm bớt rất nhiều công sức code thủ công cho phần kết nối giữa Vector Store và LLM. Thấy được sức mạnh của Amazon Titan Embedding trong việc hỗ trợ đa ngôn ngữ, rất phù hợp cho các ứng dụng tại thị trường Việt Nam. Bài học rút ra RAG là tiêu chuẩn mới: Để AI ứng dụng được trong doanh nghiệp, RAG là bắt buộc để đảm bảo tính chính xác và bảo mật dữ liệu. Hệ sinh thái toàn diện: AWS cung cấp đầy đủ từ tầng hạ tầng (Vector Store) đến tầng mô hình (Bedrock) và tầng ứng dụng (Agents), giúp việc triển khai nhanh chóng hơn rất nhiều. Một Số Hình Ảnh Khi Tham Gia Sự Kiện Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Trong trang này, tôi tổng hợp nhật ký công việc thực tập tại First Cloud Journey (FCJ). Chương trình thực tập kéo dài 12 tuần, trong đó tôi lần lượt hoàn thành các mục tiêu và nhiệm vụ hàng tuần để nắm vững các dịch vụ AWS cơ bản, triển khai dự án thực hành và làm quen với hệ sinh thái Cloud của AWS.\nTrong suốt 12 tuần, tôi đã thực hiện các công việc chính như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Tìm hiểu Networking và các dịch vụ liên quan\nTuần 3: Triển khai và quản lý EC2, EBS, Security Group\nTuần 4: Làm quen với cơ sở dữ liệu RDS và NoSQL DynamoDB\nTuần 5: Sử dụng Python SDK (Boto3) để quản lý tài nguyên AWS\nTuần 6: Tìm hiểu Amazon ElastiCache và tối ưu hóa truy xuất dữ liệu\nTuần 7: Triển khai kiến trúc Serverless với Lambda, API Gateway, SQS và SNS\nTuần 8: Tự động hóa tạo tài nguyên với CloudFormation, CDK và quản lý hệ thống với SSM\nTuần 9: Khám phá hệ sinh thái dữ liệu và Machine Learning trên AWS: Glue, Athena, QuickSight, SageMaker\nTuần 10: Giám sát hệ thống với CloudWatch, CloudTrail và sử dụng AWS Amplify\nTuần 11: Hiểu quy trình CI/CD với AWS Code Series và trải nghiệm dịch vụ AI như Polly, Rekognition\nTuần 12: Tổng kết, làm quen với FCJ, thực hành EC2 cơ bản và quản lý tài nguyên AWS cơ bản\nNhận xét chung Qua 12 tuần thực tập, tôi đã:\nTích lũy kiến thức nền tảng vững chắc về AWS, từ các dịch vụ Compute, Storage, Networking đến Database và các dịch vụ hỗ trợ. Biết triển khai và quản lý tài nguyên cơ bản, kết hợp Console và CLI một cách linh hoạt. Thực hành các dự án từ Serverless, CloudFormation, CDK, EC2, RDS, DynamoDB đến các dịch vụ AI và Machine Learning. Làm quen với môi trường thực tế tại FCJ, tương tác và phối hợp với các thành viên, nắm vững quy định, nội quy và quy trình thực tập. Những trải nghiệm này đã tạo tiền đề vững chắc cho việc triển khai các dự án cloud phức tạp hơn trong tương lai, đồng thời nâng cao kỹ năng quản lý, giám sát và tối ưu hóa hạ tầng AWS.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách tạo và quản lý chi phi với tài khoản AWS. Cách dùng console \u0026amp; CLI để tương tác và quản lý các dịch vụ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 08/09/2025 08/09/2025 3 - Tìm hiểu AWS và các loại dịch vụ cơ bản + Compute (EC2) + Storage (S3) + Networking (VPC) + Database (RDS) 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Quản lý danh tính và quyền truy cập + Cài AWS CLI \u0026amp; cấu hình + Sử dụng AWS CLI với các thao tác cơ bản 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu cách quản lý chi phí hiệu quả với AWS budget + Budget + Cost Budget, + Usage Budget + Reservation (RI) Budget + Saving plans Budget - Thực hành: + Tạo Cost Budget + Tạo Usage Budget + Tạo RI Budget + Tạo Savings Plans Budget + Dọn Dẹp Tài Nguyên 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu về dịch vụ AWS Support - Các gói hỗ trợ của AWS + Gói Basic, Developer, Business và Enterprise - Các loại yêu cầu hỗ trợ + Hỗ trợ Tài khoản và Thanh toán + Hỗ trợ nâng hạn mức dịch vụ + Hỗ trợ Kỹ thuật - Thực hành: + Chọn gói hỗ trợ Basic + Tạo yêu cầu hỗ trợ 12/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute: Cung cấp tài nguyên xử lý cho ứng dụng như máy ảo, container,\u0026hellip; Storage: Dùng để lưu trữ dữ liệu, sao lưu và phục hồi Networking: Quản lý hạ tầng mạng, bảo mật, và kết nối giữa các tài nguyên AWS. Database: Cung cấp dịch vụ quản lý cơ sở dữ liệu quan hệ và phi quan hệ. Đã tạo cấu hình và định danh AWS Free Tier account thành công.\nĐã biết tạo và quản lý Group user, User.\nBiết cách đăng nhập bằng IAM và các user trong cùng một group sẽ được dùng chung quyền được cấp.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Tạo và xóa S3 Bucket Sử dụng SNS amazon Tạo IAM group, user và thêm user Tạo và xóa acess key Tạo và cấu hình cơ bản VPS Chạy và chấm dứt EC2 Nắm được cách quản lý và giám sát chi phí trên AWS thông qua các công cụ:\nTạo và cấu hình các gói Budget (Cost, Usage, RI, Savings Plan). Biết cách dọn dẹp tài nguyên để quản lý chi phí hiệu quả. Hiểu về các gói hỗ trợ của AWS và biết cách tạo yêu cầu hỗ trợ từ trung tâm hỗ trợ.\nBasic: Miễn phí, hỗ trợ các vấn đề liên quan đến tài khoản và thanh toán từ trung tâm trợ giúp Developer: 29 USD/tháng, tư vấn kiến trúc cơ bản, và hỗ trợ kỹ thuật không giới hạn được tạo từ tài khoản gốc (root user) Business:100 USD/tháng, lựa chọn phổ biến cho các doanh nghiệp vừa và nhỏ với các hỗ trợ như: Chỉ dẫn theo Use-case cụ thể, Hỗ trợ sử dụng AWS Support API, không giới hạn các yêu cầu hỗ trợ được tạo bởi tất cả các IAM User,\u0026hellip; Enterprise: 15.000 USD/tháng, cho doanh nghiệp quy mô lớn được đảm bảo các tiêu chí bảo mẩ tiêu chuẩn và nghiêm ngặt nhất với các dịch vụ bảo mật như: về kiến trúc phần mềm, hạ tầng, hỗ trợ toàn diện về chiến lược và tối ưu chi phí, được ưu tiên chăm sóc đặc biệt các yêu cấu hỗ trợ,\u0026hellip; Làm quen với giao diện AWS Console và sử dụng tốt các thao tác cơ bản qua cả Console và CLI.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Định hướng học tập và thực hành trong tuần 2 Tìm hiểu cách xây dựng hạ tầng mạng trên AWS theo mô hình chuẩn. Nắm được các cơ chế bảo mật trong môi trường VPC. Thiết lập các hình thức kết nối an toàn giữa hệ thống nội bộ và hệ thống Cloud. Nội dung triển khai trong tuần Thứ Hoạt động chính Bắt đầu Kết thúc Tham khảo 2 Nghiên cứu tổng quan Amazon VPC, phạm vi hoạt động theo Region, AZ, CIDR; tìm hiểu các thành phần mạng như Subnet, Route Table, Internet Gateway, NAT Gateway; tìm hiểu cơ chế bảo mật bằng Security Group và Network ACL; thực hành tạo mới VPC và các thành phần cơ bản 11/08/2025 11/08/2025 3 Tìm hiểu EC2 cơ bản: loại instance, AMI, key pair, cấu hình mạng; các hình thức kết nối vào EC2; tìm hiểu Elastic IP, Reachability Analyzer, Session Manager và CloudWatch 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Triển khai hệ thống EC2 đa vùng khả dụng; tạo NAT Gateway; giám sát VPC bằng CloudWatch; thiết lập Instance Connect Endpoint, sử dụng Session Manager; thực hiện dọn dẹp toàn bộ tài nguyên sau khi hoàn thành 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Tìm hiểu các mô hình kết nối mạng: Site-to-Site VPN, Transit Gateway và VPC Peering 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Thực hành cấu hình VPN kết nối giữa AWS và môi trường giả lập on-premise; thiết lập VPC Peering và Transit Gateway 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Tổng hợp kết quả đạt được trong tuần 2 Trong tuần thứ hai, em đã tập trung tìm hiểu và xây dựng hệ thống mạng cơ bản trên AWS, đồng thời triển khai các mô hình kết nối và bảo mật phổ biến trong thực tế.\nCụ thể, em đã tự tay thiết kế và tạo thành công một hệ thống VPC hoàn chỉnh, bao gồm một VPC chính với dải địa chỉ IP 10.0.0.0/16. Bên trong VPC, em triển khai hai subnet public và private nằm ở hai Availability Zone khác nhau để đảm bảo khả năng sẵn sàng cao. Hệ thống định tuyến được cấu hình đầy đủ thông qua Route Table, Internet Gateway và NAT Gateway nhằm đảm bảo các máy chủ ở private subnet vẫn có thể truy cập Internet một cách an toàn. Đồng thời, em cũng kích hoạt VPC Flow Logs và theo dõi lưu lượng mạng thông qua CloudWatch Logs.\nBên cạnh đó, em đã nắm được quy trình triển khai và vận hành EC2, bao gồm việc tạo instance tại cả public subnet và private subnet, gán Elastic IP cho máy chủ public và thực hiện các hình thức truy cập như SSH, EC2 Instance Connect và Session Manager. Việc giám sát tài nguyên EC2 được thực hiện thông qua Amazon CloudWatch với các chỉ số về CPU, Network và trạng thái hệ thống.\nVề mặt bảo mật, em đã cấu hình thành công Security Group để kiểm soát truy cập ở mức máy chủ và Network ACL để kiểm soát ở mức subnet. Ngoài ra, em cũng thiết lập CloudWatch Alarm để cảnh báo khi tài nguyên EC2 có dấu hiệu hoạt động bất thường.\nTrong phần kết nối mạng nâng cao, em đã tìm hiểu và thực hành mô hình AWS Site-to-Site VPN, bao gồm việc tạo Virtual Private Gateway, Customer Gateway và thiết lập đường hầm IPSec giữa AWS và hệ thống on-premise mô phỏng. Đồng thời, em cũng triển khai VPC Peering nhằm kết nối hai VPC trong cùng khu vực, và làm quen với mô hình AWS Transit Gateway để kết nối nhiều mạng với nhau theo kiến trúc tập trung.\nNgoài ra, em cũng hiểu rõ hơn cách sử dụng AWS Systems Manager trong quản lý và vận hành hệ thống mà không cần truy cập trực tiếp thông qua SSH, giúp tăng mức độ bảo mật cho hạ tầng.\nThông qua các nội dung đã thực hiện, em đã nắm được nền tảng về thiết kế hạ tầng mạng, bảo mật và kết nối trên AWS, tạo tiền đề cho việc triển khai các hệ thống phức tạp hơn trong các tuần tiếp theo.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Định hướng học tập trong tuần 3 Tìm hiểu sâu về dịch vụ máy chủ ảo Amazon EC2 – nền tảng cốt lõi của hạ tầng AWS. Nắm được cách vận hành, giám sát và mở rộng hệ thống máy chủ theo mô hình thực tế. Nội dung triển khai trong tuần Thứ Hoạt động chính Bắt đầu Kết thúc Tham khảo 2 Nghiên cứu tổng quan về dịch vụ EC2 và các thành phần liên quan như: instance type, AMI, key pair, EBS, instance store, user data, meta data, auto scaling, EFS/FSx, Lightsail và MGN 11/08/2025 11/08/2025 3 Thực hành tạo EC2 trên Windows và Linux, snapshot sao lưu dữ liệu, cài đặt ứng dụng trên EC2, quản lý tài nguyên bằng tag và resource group, phân quyền với IAM và dọn dẹp tài nguyên 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Tìm hiểu và cấu hình Amazon CloudWatch: giám sát chỉ số, thu thập log, thiết lập cảnh báo và xây dựng dashboard theo dõi trạng thái hệ thống 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Nghiên cứu mô hình EC2 Auto Scaling, các cơ chế scale, launch template và elastic load balancer; thực hành triển khai hệ thống có khả năng tự động mở rộng và thu hẹp 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Làm quen với Amazon Lightsail, triển khai các instance ứng dụng và database, cấu hình load balancer, snapshot backup và nâng cấp cấu hình máy chủ 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Tổng hợp kết quả đạt được trong tuần 3 Trong tuần thứ ba, em tập trung tìm hiểu chuyên sâu về dịch vụ EC2 – thành phần quan trọng trong việc triển khai hạ tầng máy chủ trên AWS. Thông qua quá trình học tập và thực hành, em đã hiểu rõ hơn về kiến trúc của EC2 cũng như cách lựa chọn cấu hình phù hợp với từng nhu cầu sử dụng. Em có thể phân biệt được các nhóm instance phổ biến như nhóm tổng hợp, nhóm tối ưu CPU, tối ưu bộ nhớ và tối ưu lưu trữ.\nBên cạnh đó, em đã nắm được vai trò của AMI, key pair, EBS và instance store trong quá trình khởi tạo và vận hành máy chủ. Việc sử dụng user data và meta data cũng giúp em tự động hóa quá trình thiết lập môi trường ngay từ khi EC2 được khởi tạo. Ngoài ra, em cũng làm quen với EFS và FSx để phục vụ nhu cầu lưu trữ và chia sẻ dữ liệu giữa nhiều máy chủ.\nVề thực hành, em đã tự triển khai và kết nối thành công máy chủ EC2 trên cả hai hệ điều hành Windows và Linux. Em biết cách tạo snapshot để sao lưu dữ liệu và khôi phục khi cần thiết, đồng thời cài đặt được các ứng dụng web cơ bản phục vụ cho việc thử nghiệm. Việc sử dụng tag và resource group giúp em quản lý tài nguyên một cách khoa học hơn. Đồng thời, thông qua IAM, em đã biết cách giới hạn quyền truy cập nhằm đảm bảo an toàn cho hệ thống.\nTrong phần giám sát, em đã tìm hiểu và áp dụng Amazon CloudWatch để theo dõi hoạt động của hệ thống. Em cấu hình được các chỉ số giám sát EC2, thu thập log từ ứng dụng, tạo cảnh báo khi CPU hoặc lưu lượng mạng vượt ngưỡng và xây dựng dashboard tổng hợp giúp theo dõi tình trạng toàn bộ hệ thống một cách trực quan.\nVề khả năng mở rộng, em đã hiểu rõ cơ chế hoạt động của EC2 Auto Scaling, bao gồm cách mở rộng thủ công, mở rộng theo lịch và mở rộng tự động dựa trên tải thực tế. Em cũng đã triển khai thành công auto scaling group kết hợp với load balancer để đảm bảo hệ thống có khả năng tự điều chỉnh số lượng máy chủ khi lưu lượng thay đổi.\nCuối tuần, em tiếp cận thêm dịch vụ Amazon Lightsail – một nền tảng triển khai nhanh các ứng dụng phổ biến. Em đã thực hành triển khai các mô hình như website WordPress, hệ thống bán hàng PrestaShop và phần mềm kế toán Akaunting. Ngoài ra, em cũng sử dụng Lightsail Database để lưu trữ dữ liệu, Lightsail Load Balancer để phân phối tải, tạo snapshot để sao lưu và thực hiện nâng cấp cấu hình instance khi cần thiết.\nThông qua các nội dung đã thực hiện trong tuần 3, em đã nắm được quy trình triển khai, vận hành, giám sát và mở rộng hệ thống máy chủ trên AWS, tạo nền tảng vững chắc để tiếp tục học và triển khai các hệ thống thực tế ở những giai đoạn tiếp theo.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Định hướng học tập trong tuần 4 Tìm hiểu các dịch vụ lưu trữ dữ liệu trên AWS, đặc biệt là S3 và các giải pháp lưu trữ lai (hybrid). Nắm được các cơ chế sao lưu, khôi phục và chiến lược phòng chống thảm họa cho hệ thống. Thực hành triển khai các mô hình lưu trữ có tính sẵn sàng cao, an toàn và dễ mở rộng. Nội dung triển khai trong tuần Thứ Hoạt động chính Bắt đầu Kết thúc Tham khảo 2 Tìm hiểu chi tiết về Amazon S3: bucket, object, access point, các lớp lưu trữ, versioning, CORS, control access, static website, CloudFront, replication và tối ưu hiệu năng; thực hành tạo bucket, upload dữ liệu, triển khai static website và sao chép dữ liệu giữa các region 11/08/2025 11/08/2025 3 Tìm hiểu kiến trúc AWS Backup, xây dựng kế hoạch sao lưu, thiết lập thông báo qua SNS; thực hành tạo Backup Plan, theo dõi hoạt động backup và kiểm thử khả năng khôi phục 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Tìm hiểu Snow Family, Storage Gateway (File, Volume, Tape Gateway) và các khái niệm Disaster Recovery (RTO, RPO); thực hành tạo File Gateway, chia sẻ dữ liệu và kết nối với môi trường on-premise 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Tìm hiểu AWS Import/Export; thực hành import máy ảo từ VMware lên AWS và export EC2 từ AWS về môi trường on-premise 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Tìm hiểu dịch vụ Amazon FSx; thực hành triển khai hệ thống file server Multi-AZ với SSD và HDD, kiểm tra hiệu năng, giám sát, cấu hình snapshot, scale dung lượng và throughput 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Tổng hợp kết quả đạt được trong tuần 4 Trong tuần thứ tư, em tập trung tìm hiểu các giải pháp lưu trữ dữ liệu trên AWS cũng như các cơ chế sao lưu và khôi phục nhằm đảm bảo an toàn cho hệ thống.\nTrước hết, em đã nắm được cách hoạt động của Amazon S3, bao gồm cấu trúc bucket, object, access point cùng các cơ chế kiểm soát truy cập thông qua ACL, policy, CORS và versioning. Em thực hành tạo bucket, upload dữ liệu, triển khai website tĩnh trực tiếp trên S3, đồng thời tích hợp CloudFront để tăng tốc phân phối nội dung. Ngoài ra, em cũng thực hiện sao chép dữ liệu giữa các region nhằm nâng cao khả năng sẵn sàng.\nBên cạnh S3, em đã tìm hiểu các giải pháp lưu trữ kết hợp giữa on-premise và AWS thông qua Storage Gateway, bao gồm File Gateway, Volume Gateway và Tape Gateway. Việc kết nối file share từ môi trường nội bộ lên AWS giúp em hiểu rõ hơn mô hình lưu trữ hybrid trong thực tế. Em cũng tìm hiểu Snow Family và các kịch bản di chuyển dữ liệu lớn trong doanh nghiệp.\nVề sao lưu và khôi phục dữ liệu, em đã nghiên cứu kiến trúc của AWS Backup, cách xây dựng Backup Plan, cơ chế lưu trữ trong Backup Vault và quy trình khôi phục dữ liệu. Em cấu hình thành công hệ thống sao lưu tự động, tích hợp SNS để gửi thông báo và thực hiện kiểm thử restore dữ liệu. Đồng thời, em cũng hiểu rõ các chiến lược Disaster Recovery như RTO, RPO, Pilot Light, Warm Standby và Active-Active để đảm bảo khả năng vận hành liên tục cho hệ thống khi xảy ra sự cố.\nTrong phần lưu trữ file hệ thống, em đã thực hành với Amazon FSx bằng cách triển khai các mô hình Multi-AZ với ổ SSD và HDD, tạo file share, theo dõi hiệu năng, bật cơ chế chống trùng lặp dữ liệu, shadow copy và quản lý phiên làm việc của người dùng. Ngoài ra, em cũng thực hiện mở rộng dung lượng lưu trữ và thông lượng để đáp ứng nhu cầu sử dụng tăng cao.\nNgoài ra, em đã thực hành quy trình Import/Export máy ảo giữa môi trường on-premise và AWS. Cụ thể, em export máy ảo từ VMware, upload lên S3, import thành AMI và khởi chạy EC2. Ở chiều ngược lại, em cũng thực hiện export EC2 về lại môi trường ảo hóa nội bộ.\nThông qua các nội dung đã thực hiện trong tuần 4, em đã nắm được toàn cảnh về các giải pháp lưu trữ, sao lưu, khôi phục và phòng chống thảm họa trên AWS. Đây là nền tảng quan trọng để xây dựng các hệ thống có tính sẵn sàng cao, an toàn và dễ mở rộng trong thực tế.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Định hướng học tập trong tuần 5 Tìm hiểu tổng quan về mô hình bảo mật của AWS và các nguyên tắc bảo mật cốt lõi. Nắm được cách quản lý danh tính, phân quyền và xác thực người dùng trên nền tảng AWS. Thực hành các cơ chế mã hóa, giám sát và bảo vệ dữ liệu trong môi trường cloud. Nội dung triển khai trong tuần Thứ Hoạt động chính Bắt đầu Kết thúc Tham khảo 2 Tìm hiểu mô hình Shared Responsibility Model, trách nhiệm giữa AWS và khách hàng; nghiên cứu tổng quan về Amazon IAM gồm Root Account, IAM User, IAM Group, IAM Policy, IAM Role và Permission Boundary 11/08/2025 11/08/2025 3 Thực hành tạo IAM Group, IAM User, IAM Role và Assume Role; cấu hình người dùng quản trị EC2, RDS; thiết lập điều kiện Role theo IP, thời gian; tạo policy giới hạn quyền và kiểm thử tài khoản bị giới hạn 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Tìm hiểu Tag và AWS Resource Groups; thực hành gắn Tag cho EC2 bằng Console và CLI; tạo Resource Group; kiểm soát truy cập EC2 dựa trên Tag thông qua IAM Policy và kiểm thử các trường hợp bị từ chối truy cập 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Tìm hiểu Amazon Cognito, AWS Organizations, AWS Identity Center (SSO), AWS KMS và AWS Security Hub; kích hoạt Security Hub và đánh giá các bộ tiêu chuẩn bảo mật 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Thực hành AWS SSO với mô hình multi-account; tạo OU trong AWS Organizations; mã hóa dữ liệu với AWS KMS; upload dữ liệu mã hóa lên S3; bật CloudTrail và sử dụng Athena truy vấn log; kiểm thử chia sẻ dữ liệu mã hóa 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Tổng hợp kết quả đạt được trong tuần 5 Trong tuần thứ năm, em tập trung tìm hiểu sâu về hệ thống bảo mật và quản lý danh tính trên nền tảng AWS. Trước hết, em đã nắm vững mô hình chia sẻ trách nhiệm (Shared Responsibility Model), trong đó AWS chịu trách nhiệm bảo mật hạ tầng vật lý, phần cứng và các dịch vụ nền tảng, còn khách hàng chịu trách nhiệm cấu hình bảo mật dữ liệu, ứng dụng, phân quyền truy cập và các cơ chế mã hóa. Điều này giúp em hiểu rõ ranh giới trách nhiệm khi vận hành hệ thống trên môi trường cloud.\nTiếp theo, em nghiên cứu chi tiết dịch vụ Amazon Identity and Access Management (IAM). Em đã nắm được các khái niệm cốt lõi như Root Account, IAM User, IAM Group, IAM Policy, IAM Role và Permission Boundary. Thông qua quá trình thực hành, em đã tạo nhiều nhóm người dùng, cấu hình tài khoản quản trị cho từng dịch vụ như EC2, RDS, đồng thời áp dụng nguyên tắc phân quyền tối thiểu (least privilege) để hạn chế rủi ro bảo mật. Ngoài ra, em cũng thực hiện cấu hình Assume Role, giới hạn theo IP và thời gian truy cập, từ đó kiểm thử các kịch bản truy cập bị từ chối khi không thỏa điều kiện bảo mật.\nBên cạnh IAM, em đã tìm hiểu và thực hành sử dụng Tag để quản lý tài nguyên và kiểm soát quyền truy cập. Em gắn Tag cho các tài nguyên EC2 thông qua cả Console và CLI, tạo Resource Groups để gom nhóm tài nguyên theo thẻ, sau đó thiết lập IAM Policy cho phép hoặc từ chối truy cập dựa trên giá trị Tag và Region. Việc kiểm thử các trường hợp bị deny do sai Region, sai Tag hoặc không thỏa điều kiện giúp em hiểu rõ hơn cách AWS kiểm soát truy cập ở mức tài nguyên.\nTrong phần quản lý người dùng ứng dụng, em tìm hiểu dịch vụ Amazon Cognito, bao gồm User Pool để quản lý tài khoản và xác thực đăng nhập, cùng Identity Pool để cấp quyền truy cập tạm thời vào các dịch vụ AWS. Đồng thời, em cũng nghiên cứu mô hình vận hành đa tài khoản thông qua AWS Organizations và AWS Identity Center (SSO). Em đã thực hành tạo Organizational Unit (OU), phân tách môi trường, thiết lập đăng nhập tập trung bằng SSO, từ đó hiểu rõ cách quản lý tập trung trong hệ thống multi-account.\nVề bảo mật dữ liệu, em đã học cách sử dụng AWS Key Management Service (KMS) để tạo và quản lý khóa mã hóa. Em áp dụng mã hóa cho dữ liệu lưu trữ trong Amazon S3, sau đó kiểm thử việc upload, truy cập và chia sẻ dữ liệu đã được mã hóa thông qua các quyền được cấp bởi IAM và Role. Đồng thời, em bật AWS CloudTrail để ghi lại toàn bộ hoạt động của tài khoản và sử dụng Amazon Athena để truy vấn log phục vụ công tác giám sát và kiểm tra an ninh.\nNgoài ra, em cũng kích hoạt và sử dụng AWS Security Hub để tổng hợp, đánh giá các tiêu chuẩn bảo mật mặc định. Thông qua các báo cáo và cảnh báo, em hiểu được các lỗi cấu hình phổ biến cũng như cách cải thiện mức độ an toàn của hệ thống.\nThông qua các nội dung thực hiện trong tuần 5, em đã có cái nhìn toàn diện về hệ sinh thái bảo mật của AWS, từ quản lý danh tính, phân quyền truy cập, kiểm soát tài nguyên bằng Tag, đến mã hóa dữ liệu, giám sát hoạt động và đánh giá tiêu chuẩn bảo mật. Đây là nền tảng quan trọng để triển khai các hệ thống cloud an toàn và đáp ứng yêu cầu vận hành thực tế.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Định hướng học tập trong tuần 6 Tìm hiểu các dịch vụ cơ sở dữ liệu quan hệ (SQL) và phi quan hệ (NoSQL) trên nền tảng AWS. Biết cách triển khai, vận hành và sao lưu dữ liệu an toàn trong môi trường cloud. Làm quen với các cơ chế tăng tốc truy vấn bằng bộ nhớ đệm (cache) thông qua Amazon ElastiCache. Thực hành lập trình tương tác với cơ sở dữ liệu AWS thông qua Python SDK. Nội dung triển khai trong tuần Thứ Hoạt động chính Bắt đầu Kết thúc Tham khảo 2 Tìm hiểu tổng quan về Amazon RDS và Amazon Aurora; các hệ quản trị cơ sở dữ liệu như MySQL, PostgreSQL; kiến trúc Multi-AZ; cơ chế Read Replicas; sao lưu và khôi phục dữ liệu tự động 11/08/2025 11/08/2025 3 Thực hành triển khai hệ thống RDS: chuẩn bị hạ tầng gồm VPC, EC2, Security Group và DB Subnet Group; triển khai EC2 và RDS trong Private Subnet; kết nối EC2 với RDS; triển khai ứng dụng; cấu hình sao lưu tự động và dọn dẹp tài nguyên 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Tìm hiểu Amazon DynamoDB (NoSQL): cấu trúc bảng, Primary Key, Sort Key, mô hình Read/Write Capacity (On-demand, Provisioned); thực hành tạo bảng, ghi – đọc – cập nhật – truy vấn dữ liệu, tạo Global Secondary Index và truy vấn dữ liệu qua index 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Tìm hiểu AWS SDK cho Python gồm Botocore và Boto3; cấu hình AWS CLI; sử dụng Python thao tác với DynamoDB: tạo bảng, ghi, đọc, cập nhật, xóa dữ liệu, quét bảng, tải dữ liệu mẫu và xóa toàn bộ tài nguyên 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Tìm hiểu Amazon ElastiCache for Redis: cluster, node, shard; tạo Access Key cấu hình AWS CLI; tạo ElastiCache Cluster qua Console và CLI; sử dụng AWS SDK để đọc – ghi dữ liệu: string, hash, publish/subscribe và stream 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Tổng hợp kết quả đạt được trong tuần 6 Trong tuần thứ sáu, em tập trung tìm hiểu và thực hành về hệ thống cơ sở dữ liệu và các dịch vụ lưu trữ, xử lý dữ liệu trên nền tảng AWS. Trước tiên, em đã nghiên cứu dịch vụ Amazon RDS và Aurora, hiểu rõ đặc điểm của các engine cơ sở dữ liệu phổ biến như MySQL và PostgreSQL, cũng như cách AWS đảm bảo tính sẵn sàng cao thông qua kiến trúc Multi-AZ. Bên cạnh đó, em cũng nắm được cơ chế Read Replicas nhằm tăng hiệu năng đọc và khả năng mở rộng hệ thống, cùng với cơ chế sao lưu và khôi phục dữ liệu tự động để đảm bảo an toàn dữ liệu.\nTrong phần thực hành RDS, em đã triển khai hoàn chỉnh một hệ thống bao gồm EC2 và RDS trong môi trường Private Subnet. Em cấu hình Security Group và DB Subnet Group phù hợp để đảm bảo kết nối giữa ứng dụng và cơ sở dữ liệu diễn ra an toàn. Em cũng thực hiện backup tự động và kiểm thử khôi phục dữ liệu, qua đó hiểu rõ hơn quy trình vận hành thực tế của một hệ quản trị cơ sở dữ liệu trên cloud.\nTiếp theo, em tìm hiểu về Amazon DynamoDB – dịch vụ cơ sở dữ liệu NoSQL của AWS. Em nắm được cấu trúc bảng, vai trò của Partition Key và Sort Key, cũng như nguyên lý phân bổ dung lượng Read/Write theo hai chế độ On-demand và Provisioned. Trong quá trình thực hành, em đã tạo bảng dữ liệu, thực hiện các thao tác ghi, đọc, cập nhật, truy vấn dữ liệu, đồng thời xây dựng Global Secondary Index để tối ưu truy vấn theo các trường dữ liệu khác nhau.\nSong song với đó, em cũng làm quen với hệ sinh thái AWS SDK cho Python, bao gồm Botocore và Boto3. Em cấu hình AWS CLI để kết nối với tài khoản và sử dụng Python để lập trình thao tác trực tiếp với DynamoDB như tạo bảng, thêm dữ liệu, truy vấn, quét toàn bộ bảng và xóa dữ liệu. Việc lập trình tự động giúp em hiểu sâu hơn cách các ứng dụng thực tế làm việc với dịch vụ AWS thông qua API.\nNgoài ra, em còn tìm hiểu và thực hành với Amazon ElastiCache for Redis – dịch vụ bộ nhớ đệm phân tán của AWS. Em đã tạo ElastiCache Cluster, kết nối thông qua AWS SDK và thực hiện các thao tác đọc – ghi dữ liệu như set/get string, set/get hash, publish/subscribe và làm việc với stream. Thông qua đó, em hiểu được vai trò quan trọng của cache trong việc tăng tốc truy xuất dữ liệu và giảm tải cho hệ thống cơ sở dữ liệu chính.\nKết thúc tuần học, em đã có cái nhìn tương đối toàn diện về các mô hình cơ sở dữ liệu trên AWS, từ cơ sở dữ liệu quan hệ, NoSQL đến hệ thống cache. Đồng thời, em cũng nắm được cách triển khai, lập trình, sao lưu và tối ưu hiệu năng dữ liệu – đây là nền tảng quan trọng cho việc xây dựng và vận hành các hệ thống ứng dụng trên môi trường cloud.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Định hướng học tập trong tuần 7 Làm quen với kiến trúc Serverless thông qua AWS Lambda và Amazon API Gateway. Hiểu nguyên lý hoạt động của các hệ thống Event-Driven trên nền tảng AWS. Biết cách xây dựng hệ thống xử lý bất đồng bộ bằng Amazon SQS và SNS. Thực hành xây dựng API kết nối Lambda với DynamoDB và S3 để xử lý dữ liệu. Nội dung triển khai trong tuần Thứ Hoạt động chính Bắt đầu Kết thúc Tham khảo 2 Tìm hiểu về AWS Lambda: khái niệm function, cách phân quyền thông qua IAM Role; tìm hiểu Amazon API Gateway: các HTTP method, cơ chế CORS; thực hành tạo IAM Role cho Lambda, xây dựng Lambda function xử lý upload file, cấu hình API Gateway trigger Lambda và lưu dữ liệu vào DynamoDB 11/08/2025 11/08/2025 3 Thực hành tích hợp Lambda với S3 và DynamoDB: tạo Lambda xử lý ảnh, tạo S3 Bucket, xây dựng IAM Policy cho Lambda, tạo và quản lý bảng trong DynamoDB, xây dựng Lambda function ghi dữ liệu và dọn dẹp tài nguyên 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Thực hành triển khai website tĩnh với S3: tạo Bucket, bật static hosting, gán policy và upload frontend; xây dựng hệ thống CRUD với DynamoDB và Lambda, cấu hình API Gateway, kiểm thử API bằng Postman và frontend, dọn dẹp tài nguyên 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Tìm hiểu kiến trúc Event-Driven với Amazon SQS và SNS: nguyên lý publish/subscribe và message queue; thực hành tạo Queue và Topic SNS, xây dựng Lambda và API để tương tác với Queue và SNS, kiểm thử hoạt động hệ thống 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Tìm hiểu AWS Step Functions và vai trò trong việc điều phối (orchestration) các microservices trong hệ thống Serverless 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Tổng hợp kết quả đạt được trong tuần 7 Trong tuần thứ bảy, em tập trung tìm hiểu và thực hành các mô hình kiến trúc Serverless và Event-Driven trên nền tảng AWS. Trước hết, em đã nghiên cứu cách hoạt động của AWS Lambda, hiểu được cơ chế triển khai hàm xử lý không cần quản lý máy chủ, cũng như vai trò của IAM Role trong việc cấp quyền truy cập tài nguyên cho Lambda theo nguyên tắc tối thiểu (least privilege).\nSong song với đó, em tìm hiểu về Amazon API Gateway, bao gồm cách xây dựng các REST API, sử dụng các phương thức HTTP và thiết lập CORS để cho phép frontend gọi API một cách an toàn. Trong quá trình thực hành, em đã xây dựng thành công hệ thống trong đó API Gateway đóng vai trò làm cổng trung gian, kích hoạt Lambda xử lý request và ghi dữ liệu xuống DynamoDB.\nTiếp theo, em thực hành tích hợp Lambda với Amazon S3 và DynamoDB. Em đã xây dựng Lambda function để xử lý upload file lên S3, đồng thời lưu metadata xuống DynamoDB. Thông qua nội dung này, em hiểu rõ hơn quy trình xây dựng một hệ thống backend serverless hoàn chỉnh với ba thành phần chính: API Gateway – Lambda – DynamoDB.\nNgoài ra, em cũng triển khai thành công mô hình host website tĩnh bằng S3, kết hợp frontend gọi API thông qua API Gateway để thực hiện các thao tác thêm, sửa, xóa và truy vấn dữ liệu. Việc kiểm thử bằng Postman và trực tiếp trên giao diện web giúp em hiểu rõ luồng xử lý request trong môi trường thực tế.\nBên cạnh kiến trúc Serverless, em tiếp tục tìm hiểu mô hình Event-Driven thông qua Amazon SQS và SNS. Em đã tạo Queue và Topic SNS, xây dựng Lambda để xử lý message từ Queue, cũng như thực hành publish và subscribe để mô phỏng các hệ thống xử lý bất đồng bộ. Qua đó, em hiểu được vai trò của hàng đợi trong việc tách rời các thành phần trong hệ thống, tăng độ ổn định và khả năng mở rộng.\nCuối tuần, em có thêm kiến thức tổng quan về AWS Step Functions và khả năng điều phối các Lambda function trong hệ thống microservices theo từng luồng xử lý logic. Thông qua tuần học này, em đã nắm được nền tảng quan trọng của kiến trúc Serverless, Event-Driven và cách xây dựng các hệ thống backend hiện đại trên AWS với khả năng mở rộng, tiết kiệm chi phí và dễ bảo trì.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Hiểu và triển khai tự động hóa tạo tài nguyên AWS bằng CloudFormation và AWS CDK. Quản lý cấu hình hệ thống và giám sát phiên làm việc với AWS Systems Manager. Biết cách kết nối các thành phần hạ tầng (EC2, Lambda, API Gateway, S3) theo mô hình Infrastructure as Code. Các công việc triển khai trong tuần Thứ Hoạt động Ngày bắt đầu Ngày kết thúc Tham khảo 2 Tìm hiểu AWS CloudFormation và Cloud9: cấu trúc template JSON/YAML, khái niệm Stack, Drift Detection; Thực hành: tạo CloudFormation template cơ bản sử dụng Cloud9 11/08/2025 11/08/2025 3 Thực hành nâng cao CloudFormation: triển khai Lambda function, tạo Stack, kết nối EC2, ánh xạ các tài nguyên với StackSets, kiểm tra Drift Detection, dọn dẹp tài nguyên 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Tìm hiểu AWS Systems Manager (SSM): Patch Manager, Run Command, Session Manager; Thực hành: tạo EC2 instance, gán IAM Role, cấu hình Patch Manager và Run Command, theo dõi session, dọn dẹp tài nguyên 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Tìm hiểu AWS CDK và triển khai với VS Code: tạo EC2 public, cấu hình môi trường phát triển, tạo ECS cluster, application, API Gateway + Load Balancer, Lambda, S3; triển khai Stack và Nested Stack, dọn dẹp tài nguyên 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Thực hành Session Manager: tạo EC2 private/public, gán IAM Role, kết nối từ máy chủ public đến private, cập nhật IAM Role truy cập S3, tạo S3 bucket và S3 Gateway endpoint, theo dõi session logs, cấu hình Port Forwarding, dọn dẹp tài nguyên 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8 Trong tuần này, em tập trung học và thực hành các giải pháp Infrastructure as Code và quản lý cấu hình hệ thống:\nAWS CloudFormation \u0026amp; CDK\nHiểu rõ cách tạo, triển khai và quản lý Stack, Nested Stack, StackSets. Thực hành xây dựng template JSON/YAML để tự động tạo Lambda, EC2, S3, API Gateway. Áp dụng CloudFormation Drift Detection để phát hiện sự khác biệt giữa template và tài nguyên thực tế. Sử dụng AWS CDK với VS Code để triển khai hạ tầng linh hoạt, dễ bảo trì và mở rộng. AWS Systems Manager (SSM)\nQuản lý EC2 từ xa thông qua Session Manager, không cần SSH trực tiếp. Cấu hình Patch Manager và Run Command để tự động cập nhật, vận hành EC2. Theo dõi logs session và sử dụng Port Forwarding để truy cập EC2 Private. Quản lý hạ tầng tự động\nKết nối các thành phần hạ tầng (Lambda, API Gateway, EC2, S3) theo kiến trúc IaC. Hiểu luồng triển khai, cập nhật và xóa tài nguyên một cách an toàn. Biết dọn dẹp tài nguyên sau thực hành để tối ưu chi phí và tránh dư thừa. Kỹ năng bổ sung\nLàm quen với Cloud9 để phát triển, chỉnh sửa template CloudFormation và CDK. Hiểu nguyên lý vận hành và giám sát các phiên làm việc EC2 private/public. Có khả năng triển khai hệ thống backend Serverless và containerized với API Gateway và Load Balancer. Qua tuần này, em đã nâng cao kỹ năng tự động hóa hạ tầng AWS, hiểu cách quản lý và theo dõi hệ thống một cách hiệu quả, sẵn sàng triển khai các môi trường phức tạp hơn trong các tuần tiếp theo.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Làm quen với hệ sinh thái dữ liệu và Machine Learning trên AWS. Hiểu các dịch vụ AI/ML trên AWS và biết cách triển khai các pipeline phân tích dữ liệu. Biết sử dụng các dịch vụ AI sẵn có để xử lý dữ liệu, nhận diện, phân tích và tạo dự đoán. Các công việc cần triển khai Thứ Hoạt động Ngày bắt đầu Ngày kết thúc Tham khảo 2 Tìm hiểu AWS Glue (Crawler), Amazon Athena, Amazon QuickSight, Amazon SageMaker 11/08/2025 11/08/2025 3 Thực hành phân tích dữ liệu: tạo IAM Role \u0026amp; Policy, tạo S3 Bucket, triển khai Glue Crawler, tạo notebook với Glue Studio, phân tích dữ liệu với Athena, trực quan hóa với QuickSight, dọn dẹp tài nguyên 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Thực hành SageMaker: tạo SageMaker Studio, chuẩn bị dataset, phân tích và export dữ liệu lên S3, train và tinh chỉnh mô hình ML, triển khai và đánh giá hiệu suất, tinh chỉnh mô hình tự động, dọn dẹp tài nguyên 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Tìm hiểu Amazon Bedrock: Foundation Model, Bedrock Agents, Knowledge Bases, Bedrock Inference Features 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Tìm hiểu Pre-trained AI Services: Rekognition, Translate, Textract, Transcribe, Polly, Comprehend, Kendra, Lookout, Personalize 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9 Trong tuần này, em tập trung vào hệ sinh thái dữ liệu và Machine Learning trên AWS, kết hợp thực hành và tìm hiểu các dịch vụ AI sẵn có:\nAWS Glue, Athena và QuickSight\nHiểu cách Glue Crawler tự động phát hiện và catalog dữ liệu từ S3. Sử dụng Athena để query dữ liệu trực tiếp từ S3 với SQL. Trực quan hóa dữ liệu với QuickSight, tạo báo cáo động và dashboard. Amazon SageMaker\nTạo và sử dụng SageMaker Studio để chuẩn bị dataset, train và tune mô hình ML. Hiểu luồng triển khai từ dữ liệu raw tới mô hình huấn luyện, đánh giá và xuất kết quả. Thực hành deploy mô hình và kiểm thử hiệu suất, bao gồm hyperparameter tuning tự động. Amazon Bedrock và Pre-trained AI Services\nNắm được cách sử dụng các Foundation Model, Bedrock Agents, và Knowledge Bases. Hiểu tính năng inference trên Bedrock để triển khai AI nhanh chóng. Thử nghiệm các dịch vụ AI sẵn có: Rekognition: nhận diện hình ảnh/video. Translate \u0026amp; Transcribe: dịch thuật và chuyển giọng nói sang văn bản. Textract \u0026amp; Comprehend: trích xuất dữ liệu và phân tích ngôn ngữ. Polly: tổng hợp giọng nói từ văn bản. Kendra \u0026amp; Lookout: tìm kiếm thông tin và giám sát dữ liệu. Personalize: tạo hệ thống đề xuất thông minh. Kỹ năng bổ sung\nQuản lý IAM Role, Policy và quyền truy cập để bảo mật dữ liệu ML. Kết nối dữ liệu giữa S3, Glue, SageMaker và QuickSight để xây dựng pipeline hoàn chỉnh. Dọn dẹp tài nguyên sau thực hành để tối ưu chi phí. Qua tuần này, em đã có khả năng triển khai pipeline dữ liệu và ML trên AWS, hiểu cách kết hợp các dịch vụ để phân tích, trực quan hóa và triển khai mô hình Machine Learning, đồng thời làm quen với các dịch vụ AI sẵn có để tăng tốc phát triển ứng dụng thông minh.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "FoodMind Recommender Platform For Prompt-IPoG Giải pháp AWS Serverless hợp nhất cho việc theo dõi và gợi ý bữa ăn cá nhân hóa. 1. Tóm tắt điều hành FoodMind Recommender Platform là nền tảng web thông minh được thiết kế để trở thành một trợ lí ăn uống cá nhân thông minh. Nền tảng tự động tính toán calo mục tiêu (TDEE) dựa trên hồ sơ người dùng, sử dụng AWS Bedrock (AI Tạo sinh) để cho phép người dùng ghi log bữa ăn bằng ngôn ngữ tự nhiên (ví dụ: \u0026ldquo;tôi vừa ăn 1 bát phở bò\u0026rdquo;). Hệ thống cung cấp một tính năng gợi ý bữa ăn (Sáng/Trưa/Tối) thông minh, tự động \u0026ldquo;lọc\u0026rdquo; các món ăn dựa trên mục tiêu calo và các ràng buộc sức khỏe (ví dụ: \u0026ldquo;dị ứng\u0026rdquo;, \u0026ldquo;bệnh gout\u0026rdquo;) của người dùng.\nToàn bộ giải pháp được xây dựng trên kiến trúc serverless với giao diện sử dụng AWS Amplify (Frontend), API Gateway, AWS Lambda, và Amazon DynamoDB (Backend). Cho phép người dùng có thể nhận được gợi ý các món ăn trong ngày dựa trên lượng calo được tính toán theo người dùng sử dụng cần tiêu thụ trong ngày. Dữ liệu được lưu trữ và truy vấn qua Amazon DynamoDB, đảm bảo hiệu năng cao và mở rộng linh hoạt.\nGiải pháp tập trung vào sự kết hợp giữa AI và dữ liệu thực tế để hỗ trợ ra quyết định tìm món ăn linh hoạt và thiết kế dashboard để có thể xem quá trình theo dõi bữa ăn hàng ngày hiệu quả.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nNhiều người dùng gặp khó khăn trong việc quản lý chế độ ăn uống hàng ngày — không biết nên ăn bao nhiêu calo, món nào phù hợp với mục tiêu cá nhân cho mỗi ngày. Việc ghi chép thủ công và tra cứu dinh dưỡng gây mất thời gian, thiếu chính xác và không có tính cá nhân hóa.\nGiải pháp\nFoodMind Recommender Platform ứng dụng AI và AWS Cloud để tự động hóa toàn bộ quy trình theo dõi và gợi ý bữa ăn:\nTự động hóa Mục tiêu: Hệ thống tự động tính toán Calo Mục tiêu cho người dùng (dựa trên công thức Mifflin-St Jeor) ngay khi họ cập nhật hồ sơ. Tự động hóa Gợi ý: Hệ thống cung cấp API GET /recommendations sử dụng \u0026ldquo;logic nghiệp vụ\u0026rdquo; (do Lambda thực thi) để \u0026ldquo;lọc\u0026rdquo; (filter) kho dữ liệu món ăn, dựa trên Calo Mục tiêu (ví dụ: bữa trưa \u0026lt; 700 calo) và Luật cấm Bệnh lý (ví dụ: không chứa \u0026ldquo;thịt đỏ\u0026rdquo; cho bệnh gout). Tự động hóa Ghi log (AI Logging): Hệ thống cung cấp API POST /log-food sử dụng AWS Bedrock để \u0026ldquo;bóc tách\u0026rdquo; (parse) ngôn ngữ tự nhiên của người dùng. Hệ thống tự tra cứu calo và lưu vào nhật ký. Tự động hóa Học hỏi: Khi người dùng log một món ăn mới (ví dụ: \u0026ldquo;bún đậu mắm tôm\u0026rdquo;) mà hệ thống không biết, AWS Bedrock sẽ được dùng để \u0026ldquo;ước tính\u0026rdquo; calo và \u0026ldquo;tự động lưu\u0026rdquo; món mới này vào kho tri thức. Theo dõi Trực quan: Cung cấp dashboard (trên Amplify) hiển thị lịch sử ăn uống 7 ngày qua, giúp người dùng quan sát và theo dõi chế độ ăn uống cá nhân. Người dùng chỉ cần nhập thông tin, hệ thống sẽ tự động hiểu, phân tích và đề xuất–gợi ý bữa ăn phù hợp với sức khỏe và mục tiêu cá nhân.\nLợi ích và hoàn vốn đầu tư (ROI)\nTiết kiệm thời gian theo dõi dinh dưỡng, loại bỏ thao tác thủ công. Mang đến trải nghiệm AI thực tế, có tính cá nhân hóa cao. Tạo cơ sở dữ liệu chuẩn hóa cho nghiên cứu về AI trong lĩnh vực ẩm thực và cá nhân hóa bữa ăn. Chi phí thấp nhờ kiến trúc serverless. Dễ mở rộng và tái sử dụng mô hình cho các ứng dụng chăm sóc sức khỏe khác. ROI ước tính: hoàn vốn trong 6 tháng thông qua tiết kiệm thời gian phát triển và tái sử dụng mô hình AI đã có sẵn. Chi phí ước tính: khoảng 10–15 USD/tháng. 3. Kiến trúc giải pháp Nền tảng được xây dựng hoàn toàn trên mô hình AI-as-a-Service kết hợp AWS Serverless, đảm bảo hiệu năng cao, bảo mật và khả năng mở rộng linh hoạt. Dữ liệu dĩnh dưỡng về lượng calo của các món ăn được thu thập lưu trữ trong Amazon DynamoDB, sau đó sẽ gợi ý bữa ăn dựa phù hợp với lượng tính toán Calo mục tiêu. Amazon Bedrock được sử dụng để phân tích xử lý ngôn ngữ tự nhiên của người dùng tra cứu Calo món ăn và lưu vào Amazon DynamoDB. AWS Amplify lưu trữ giao diện web Next.js và Amazon Cognito đảm bảo xác thực người dùng an toàn. Kiến trúc được trình bày chi tiết bên dưới:\nDịch vụ AWS sử dụng\nAWS Amplify: Triển khai và lưu trữ giao diện web của nền tảng (Next.js), kết nối CI/CD trực tiếp với GitLab để tự động build và deploy. Amazon Route 53 + AWS WAF + Amazon CloudFront: Tầng Edge bảo vệ và phân phối nội dung nhanh chóng, đảm bảo bảo mật và hiệu năng truy cập toàn cầu. Amazon Cognito: Quản lý xác thực người dùng, đăng nhập và phân quyền truy cập an toàn cho từng tài khoản. Amazon API Gateway: Cung cấp endpoint cho các tác vụ như GET /Recommendation, POST /Log, GET /Dashboard, kết nối trực tiếp với Lambda. AWS Lambda (Private Subnet): Xử lý logic ứng dụng, gọi Bedrock và DynamoDB thông qua các VPC Endpoint để đảm bảo bảo mật và hiệu năng. AWS Bedrock: Sinh mô tả món ăn, chuẩn hóa log bữa ăn bằng ngôn ngữ tự nhiên và lưu vào DynamoDB phục vụ gợi ý bữa ăn cá nhân hóa. Amazon DynamoDB: Lưu trữ dữ liệu người dùng, nhật ký ăn uống, mục tiêu calo, và dữ liệu gợi ý – đảm bảo khả năng mở rộng linh hoạt. AWS Secrets Manager: Bảo mật thông tin xác thực (API Key, Bedrock credentials) cho Lambda và dịch vụ backend. Amazon CloudWatch \u0026amp; AWS CloudTrail: Theo dõi log, truy cập và hiệu năng toàn hệ thống; hỗ trợ giám sát và khôi phục sự cố. Amazon S3: Lưu trữ log. AWS IAM: Quản lý phân quyền truy cập chi tiết giữa các dịch vụ và người dùng. Amazon VPC: Cách ly Lambda trong subnet riêng, đảm bảo kết nối an toàn nội bộ giữa Lambda – DynamoDB – Bedrock.\nThiết kế thành phần\nQuản lý người dùng: Amazon Cognito quản lý quyền truy cập của người dùng. Phân phối \u0026amp; Bảo vệ truy cập: Route 53 định tuyến tên miền, AWS WAF bảo vệ khỏi tấn công web (SQL Injection, DDoS) và CloudFront tăng tốc độ tải nội dung và phân phối toàn cầu. Giao diện web: Amplify lưu trữ ứng dụng Next.js. Ghi nhật ký \u0026amp; gợi ý bữa ăn: Người dùng nhập dữ liệu (text) lưu vào DynamoDB, Lambda gợi ý món ăn theo số tính toán Calo. Phân tích bữa ăn: Lambda gọi Bedrock xử lý thông tin bữa ăn bằng ngôn ngữ tự nhiên của user nhập vào, bóc tách và tìm nhật ký Calo của món và lưu lại DynamoDB nếu món mới. Hiển thị dashboard: Amplify hiển thị biểu đồ calo theo ngày/tuần/tháng sau khi user cập nhật bữa ăn. Xác thực \u0026amp; bảo mật: Cognito đảm bảo đăng nhập an toàn và quản lý user. Giám sát \u0026amp; theo dõi: Amazon CloudWatch theo dõi log, hiệu năng Lambda, AWS CloudTrail lưu lại lịch sử thao tác và truy cập dịch vụ. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nNghiên cứu và Thiết kế: Thiết kế pipeline AI + Cloud, kiểm tra tính khả thi và vẽ sơ đồ hệ thống AWS (5 Tuần đầu tiên). Tính toán chi phí và tối ưu giải pháp: Kiểm tra lại chi phí các dịch vụ trong kiến trúc để tối ưu chi phí (Tuần 6). Phát triển, Kiểm thử và triển khai: Lưu dữ liệu ban đầu, sau đó tạo giao diện wed với Next.js, kiểm thử các luồng tính năng API, tốc độ và vận hành sản phẩm (Tuần 7 - tuần 11). Yêu cầu kỹ thuật\nDữ liệu Calo món ăn: Thu thập dữ liệu ban đầu và dùng script AWS SDK (Boto3) để nạp vào DynamoDB. Nền tảng gợi ý quán ăn: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), S3 (bucket), Cognito. Kiến thức thực tế về AWS Serverless (Lambda, DynamoDB, API Gateway), thiết kế schema DynamoDB (PK, SK), và cách dùng Bedrock API. 5. Lộ trình \u0026amp; Mốc triển khai Thực tập (Tháng 1–3): Tháng 1: Học và làm chủ các dịch vụ AWS. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Theo dõi, cải tiến hệ thống gợi ý và mở rộng dữ liệu trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator. Hoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Amplify: 0.50 USD/tháng (~100 MB, traffic thấp).\nAWS Lambda: 0.20-0.30 USD/tháng ( 100.000 request/tháng, thời gian chạy trung bình \u0026lt;1s ).\nAmazon API Gateway: 0.10-o.20 USD/tháng ( 50.000 request REST API/tháng).\nAmazon DynamoDB: 0.10-0.30 USD/tháng ( 50 MB dữ liệu, ~20.000 request/tháng).\nAmazon S3 (lưu trữ log/back-up): 0.10 USD/tháng (\u0026lt;2GB).\nAWS Bedrock: 3,00-500 USD/tháng ( vài nghìn token/tháng).\nCloudWatch + CloudTrail + IAM etc: ~ 0.10-USD.\nAmazon Cognito: 0.00 USD/tháng ( \u0026lt;50 người dùng hoạt động (Free Tier)).\nTổng: ~4-6 USD/tháng, ~50-75 USD/12 tháng.\n7. Đánh giá rủi ro Ma trận rủi ro\nLỗi AI xử lý sai: Ảnh hưởng cao, xác suất thấp. Quá tải request: Ảnh hưởng trung bình, xác suất Thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Lỗi logic: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nSai lệch AI: Dùng \u0026ldquo;prompt engineering\u0026rdquo; kỹ lưỡng. Quá tải request API: Giới hạn truy cập qua API Gateway. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Logic: Điều chình code kĩ lưỡng với các hàm lambda. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Trải nghiệm người dùng nâng cao: Cung cấp một trợ lý bữa ăn \u0026ldquo;thông minh\u0026rdquo;, xóa bỏ mọi rào cản thủ công trong việc ghi log và chọn món.\nTích hợp AI thực tế: Ứng dụng Bedrock trong hệ thống sản phẩm hoàn chỉnh.\nTạo nền tảng dữ liệu dinh dưỡng: Có thể mở rộng, phục vụ nghiên cứu AI \u0026amp; y tế.\nKhả năng mở rộng: tích hợp thêm phân tích hình ảnh món ăn, chat AI coach, và ứng dụng di động.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Hiểu và triển khai giám sát hệ thống với Amazon CloudWatch. Nắm được cách AWS CloudTrail ghi lại hoạt động API và quản lý log theo thời gian thực. Biết cách giám sát ứng dụng serverless và frontend/backend với AWS Amplify. Các công việc cần triển khai Thứ Hoạt động Ngày bắt đầu Ngày kết thúc Tham khảo 2 Tìm hiểu Amazon CloudWatch: Metrics, Logs, Alarms, Events, Dashboards, AWS X-Ray 11/08/2025 11/08/2025 3 Thực hành CloudWatch: tạo IAM Role \u0026amp; Policy, cấu hình EC2, cài đặt CloudWatch Metrics \u0026amp; Logs, tạo Alarm, tạo Dashboard, dọn dẹp tài nguyên 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Tìm hiểu AWS CloudTrail: Trails, Event (Read/Write/All), CloudTrail Insights 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Tìm hiểu AWS Amplify: Frontend, Backend, Storage, Authentication 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Thực hành: Giám sát Lambda với CloudWatch \u0026amp; X-Ray, host source code trên Amplify, tạo custom metric, Alarm, gỡ lỗi logs, giám sát với X-Ray, dọn dẹp tài nguyên 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10 Trong tuần này, em tập trung vào giám sát hệ thống và quản lý hoạt động trên AWS, kết hợp thực hành với các dịch vụ CloudWatch, CloudTrail và Amplify:\nAmazon CloudWatch\nHiểu và sử dụng Metrics để giám sát tài nguyên EC2, Lambda, DynamoDB. Thiết lập Logs để theo dõi chi tiết các hoạt động ứng dụng và hạ tầng. Tạo Alarms để cảnh báo khi có sự cố hoặc vượt ngưỡng định sẵn. Thiết kế Dashboard tổng quan theo dõi các tài nguyên AWS. Sử dụng X-Ray để debug và phân tích hiệu suất của Lambda và API Gateway. AWS CloudTrail\nTìm hiểu cách ghi lại toàn bộ API call, theo dõi Read/Write events. Sử dụng CloudTrail Insights để phát hiện hành vi bất thường trong hệ thống. Kết hợp với CloudWatch để lập alert và tự động hóa phản hồi khi có sự kiện quan trọng. AWS Amplify\nHost frontend/backend ứng dụng nhanh chóng. Triển khai authentication và storage để tích hợp với Lambda và DynamoDB. Giám sát hoạt động ứng dụng thông qua CloudWatch Logs và X-Ray. Kỹ năng bổ sung\nQuản lý IAM Role \u0026amp; Policy để bảo mật và phân quyền đúng mức. Kết hợp CLI và Console để quản lý đồng thời các tài nguyên AWS. Lập kế hoạch cleanup tài nguyên sau thực hành để tối ưu chi phí. Qua tuần này, em đã có khả năng giám sát hệ thống AWS theo thời gian thực, debug ứng dụng serverless, tạo cảnh báo và dashboard, đồng thời quản lý tài nguyên frontend/backend với Amplify một cách hiệu quả.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Hiểu quy trình CI/CD và các công cụ hỗ trợ trên AWS. Trải nghiệm và nắm bắt các dịch vụ AI pre-trained của Amazon. Các công việc cần triển khai Thứ Hoạt động Ngày bắt đầu Ngày kết thúc Tham khảo 2 Tham gia Event: Generative AI with Amazon Bedrock + Cập nhật kiến thức về các Foundation Model trên Amazon Bedrock + Hiểu rõ hơn các dịch vụ Pre-trained AI Service 11/08/2025 11/08/2025 3 Tìm hiểu các dịch vụ CI/CD trên AWS: + AWS CodeCommit + AWS CodeBuild + AWS CodeDeploy + AWS CodePipeline 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 Tìm hiểu và thực hành AWS Elastic Beanstalk: + Application \u0026amp; Environment + Tạo CloudFormation Stack + Kết nối EC2 instance và cài database + Triển khai và cập nhật ứng dụng trên Elastic Beanstalk + Kiểm tra trạng thái môi trường và truy vấn thông tin máy chủ EC2 + Dọn dẹp tài nguyên 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 Thực hành Amazon Polly: + Cài đặt DynamoDB + Khám phá tính năng chuyển văn bản thành giọng nói (TTS) + Tạo Speech và speech marks bằng CLI và SDK Java 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 Thực hành Amazon Rekognition: + Tạo Cognito Identity Pool + Phát hiện đối tượng và nhận diện khuôn mặt + Thử nghiệm ứng dụng tìm người + Gắn EBS volume cho EC2 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11 Trong tuần này, em đã tập trung vào triển khai CI/CD, sử dụng Elastic Beanstalk và trải nghiệm AI Services của AWS, với các kết quả chính như sau:\nCI/CD trên AWS\nHiểu quy trình phát triển phần mềm tự động với CodeCommit, CodeBuild, CodeDeploy, CodePipeline. Biết cách quản lý source code, xây dựng, test và triển khai ứng dụng tự động. AWS Elastic Beanstalk\nTriển khai ứng dụng web nhanh chóng trên môi trường quản lý sẵn. Tạo và cập nhật stack thông qua CloudFormation, kết nối EC2 instance và database. Kiểm tra và giám sát trạng thái môi trường, truy vấn thông tin server. Amazon AI Services\nAmazon Polly: chuyển văn bản thành giọng nói, tạo speech marks, tích hợp với DynamoDB. Amazon Rekognition: phát hiện đối tượng, nhận diện khuôn mặt và thử nghiệm ứng dụng tìm người. Thiết lập Cognito Identity Pool để quản lý quyền truy cập người dùng. Kỹ năng bổ sung\nQuản lý IAM Role \u0026amp; Policy để phân quyền đúng mức cho các dịch vụ. Sử dụng song song Console và CLI để quản lý, kiểm tra và cleanup tài nguyên AWS. Nắm được cách kết hợp các dịch vụ CI/CD, compute và AI để triển khai ứng dụng end-to-end. Qua tuần này, em đã có khả năng triển khai ứng dụng web với CI/CD, trải nghiệm dịch vụ AI pre-trained và quản lý toàn bộ pipeline từ code đến deployment, đồng thời thực hành giám sát và bảo mật tài nguyên AWS.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Cloud Day\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: Generative AI with Amazon Bedrock\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. {\r\u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;,\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;,\r\u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34;\r],\r\u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Đảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/1-worklog/1.12-week12/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:44761/AWS_Intern_Worklog/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]